{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_ml_guide_03_evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EJ8QzNWClvH-E2RXAQ0gzxLs-nblIKQH",
      "authorship_tag": "ABX9TyPayVt751YfD0Gb/fc5cEgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johyunkang/py_pandas/blob/main/python_ml_guide_03_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXTxBth4Rper"
      },
      "source": [
        "## 01 정확도 (Accuracy)\n",
        "\n",
        "$ 정확도(accuracy) = \\dfrac {예측 결과가 동일한 데이터 건수} {전체 예측 데이터 건수}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r57JJhDXRTLJ"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "  # fit() 메서드는 아무것도 학습하지 않음\n",
        "  def fit(self, X, y=None):\n",
        "    pass\n",
        "\n",
        "  # predict() 메서드는 단순히 Sex 피처가 남자(1)면 0, 여자(0)면 1로 예측\n",
        "  def predict(self, X):\n",
        "    pred = np.zeros((X.shape[0], 1))\n",
        "    for i in range(X.shape[0]) :\n",
        "      if(X['Sex'].iloc[i] = 1) :\n",
        "        pred[i] = 0\n",
        "      else :\n",
        "        pred[i] = 1\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olTGrbPabWSS"
      },
      "source": [
        "#### MNIST 데이터 세트를 이용하여 값이 7인것만 True, 나머지 숫자는 모두 False로 변환 한 이진 분류 문제\n",
        "\n",
        "![mnist-binary-classfi](https://user-images.githubusercontent.com/291782/138015598-e638a983-4c43-4df0-af89-36c2c647bcb6.png)\n",
        "\n",
        "\n",
        "**정확도 평가 지표의 맹점**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ejPxoQibmij",
        "outputId": "10fec83d-aff7-4a1d-d3fb-06ba3cbbbb1a"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MyFakeClassifier(BaseEstimator) :\n",
        "    def fit(self, X, y) :\n",
        "        pass\n",
        "\n",
        "    # 입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0 값으로 만들어서 반환\n",
        "    def predict(self, X) :\n",
        "        return np.zeros((len(X), 1), dtype=bool)\n",
        "\n",
        "# 사이킷런의 내장 데이터 세트인 load_digits() 이용해 MNIST 데이터 로딩\n",
        "digits = load_digits()\n",
        "\n",
        "# digits 번호가 7이면 True이고 이를 astype(int)로 1로 변환\n",
        "# 7 이 아니면 False 이고 0으로 변환\n",
        "y = (digits.target == 7).astype(int)\n",
        "x_train, x_test, y_train, y_test = train_test_split(digits.data, y, random_state = 11)\n",
        "\n",
        "# 불균형한 레이블 데이터 세트 확인\n",
        "print('레이블 테스트 세트 크기:', y_test.shape)\n",
        "print('테스트 세트 레이블 0과 1의 분포')\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "# Dummy Classifier로 학습 / 예측 / 정확도 평가\n",
        "fake_clf = MyFakeClassifier()\n",
        "fake_clf.fit(x_train, y_train)\n",
        "fake_pred = fake_clf.predict(x_test)\n",
        "print('\\n 모든 예측을 0으로 하여도 정확도는:{0:.3f}'.format(accuracy_score(y_test, fake_pred)))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "레이블 테스트 세트 크기: (450,)\n",
            "테스트 세트 레이블 0과 1의 분포\n",
            "0    405\n",
            "1     45\n",
            "dtype: int64\n",
            "\n",
            " 모든 예측을 0으로 하여도 정확도는:0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRqnUua3ex-J"
      },
      "source": [
        "## 02 오차행렬 (Confusion Matrix)\n",
        "\n",
        "![confusion-matrix-02](https://user-images.githubusercontent.com/291782/138031897-d991171d-369f-4662-900f-1cffacb38d9c.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUvhVSBDHV7b",
        "outputId": "fa515a51-86cd-4763-e4c4-6c67d4afe2db"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test, fake_pred)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[405,   0],\n",
              "       [ 45,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYpV41CHHo3C"
      },
      "source": [
        "위의 표시된 confusion_matrix() 값이 위 이미지와 동일한 위치이다.\n",
        "- TN : array[0,0]으로 405\n",
        "- FP : array[0,1] 으로 0\n",
        "- FN : array[1,0] 으로 45\n",
        "- TP : array[1,1] 으로 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtCxYLK4J69P"
      },
      "source": [
        "정밀도 (Precision) = TP / (TP + FP)\n",
        "\n",
        "재현율 (Recall) = TP / (TP + FN) = 민감도(Sensitivity) = TPR (True Positive Rate)\n",
        "\n",
        "재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
        "- 예) 암판단 모델 (암:Positive, 암X:Negative) : 암인데 암이 아닌것으로 판단하면 생명을 앗아감 \n",
        "- 암이 아닌것을 암으로 판단한 경우는 다시 한 번 재검사 하는 수준의 비용만 발생\n",
        "\n",
        "\n",
        "정밀도가 중요한 지표인 경우 (실제 Negative 음성인 데이터 예측을, Positive 양성으로 잘못 판단하게 되면 업무상 큰 영향)\n",
        "- 예) 스팸메일 : 실제 Positive인 스팸 메일을 Negative인 일반 메일로 분류하더라도 사용자가 불편을 느끼는 정도지만,\n",
        "- 실제 Negative 인 일반 메일을 Positive인 스팸 메일로 분류할 경우 메일을 받지 못해 업무에 차질이 생김\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxCrijrAcr7v",
        "outputId": "4590f187-375d-4b2f-e172-42339e33b6be"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "import sklearn.preprocessing\n",
        "\n",
        "def get_clf_eval(y_test, pred) :\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    print('정확도(accuracy):{0:.4f}, 정밀도(precision):{1:.4f}, 재현율(recall):{2:.4f}'.format(accuracy, precision, recall))\n",
        "\n",
        "\n",
        "# null 처리 함수\n",
        "def fillna(df):\n",
        "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "  df['Cabin'].fillna('N', inplace=True)\n",
        "  df['Embarked'].fillna('N', inplace=True)\n",
        "  df['Fare'].fillna(0, inplace=True)\n",
        " \n",
        "  return df\n",
        "\n",
        "\n",
        "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
        "def drop_features(df):\n",
        "  df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "# 레이블 인코딩 수행\n",
        "def format_features(df):\n",
        "  df['Cabin'] = df['Cabin'].str[:1] # 앞자리 대문자 1자리만 잘라내기\n",
        "  features = ['Cabin', 'Sex', 'Embarked']\n",
        "  for feature in features:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(df[feature])\n",
        "    df[feature] = le.transform(df[feature])\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "# 앞에서 설정한  데이터 전처리 함수 호출\n",
        "def transform_features(df):\n",
        "  df = fillna(df)\n",
        "  df = drop_features(df)\n",
        "  df = format_features(df)\n",
        "  return df\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터 / 테스트 데이터 분할\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/titanic/train.csv')\n",
        "y_df = df['Survived']\n",
        "x_df = df.drop('Survived', axis = 1)\n",
        "x_df = transform_features(x_df)\n",
        "print(x_df)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size = 0.2, random_state = 11)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(x_train, y_train)\n",
        "pred = lr.predict(x_test)\n",
        "\n",
        "print('\\n\\n## 오차행렬, 정확도, 정밀도, 재현율 등 출력 ##\\n')\n",
        "get_clf_eval(y_test, pred)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
            "0         3    1  22.000000      1      0   7.2500      7         3\n",
            "1         1    0  38.000000      1      0  71.2833      2         0\n",
            "2         3    0  26.000000      0      0   7.9250      7         3\n",
            "3         1    0  35.000000      1      0  53.1000      2         3\n",
            "4         3    1  35.000000      0      0   8.0500      7         3\n",
            "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
            "886       2    1  27.000000      0      0  13.0000      7         3\n",
            "887       1    0  19.000000      0      0  30.0000      1         3\n",
            "888       3    0  29.699118      1      2  23.4500      7         3\n",
            "889       1    1  26.000000      0      0  30.0000      2         0\n",
            "890       3    1  32.000000      0      0   7.7500      7         2\n",
            "\n",
            "[891 rows x 8 columns]\n",
            "\n",
            "\n",
            "## 오차행렬, 정확도, 정밀도, 재현율 등 출력 ##\n",
            "\n",
            "오차 행렬\n",
            "[[104  14]\n",
            " [ 13  48]]\n",
            "정확도(accuracy):0.8492, 정밀도(precision):0.7742, 재현율(recall):0.7869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLepmzGWimp7"
      },
      "source": [
        "#### 정밀도와 재현율 트레이드 오프(trade-off)\n",
        "\n",
        "일반적으로 이진 분류에서는 임곗값(예측확률)을 0.5, 즉 50%로 정하고 기준값 보다 크면 Positive, 작으면 Negative로 결정함\n",
        "\n",
        "**predict_proba()** : 예측 확률 변환 메서드\n",
        "- 입력 파라미터 : predict() 메서드와 동일하게 보통 테스트 피처 데이터 세트를 입력\n",
        "- 반환 값\n",
        " - 개별 클래스와 예측확률을 ndarray m x n (m:입력 값의 레코드 수, n: 클래스 값 유형) 형태로 반환\n",
        " - 입력 테스트 데이터 세트의 표본수가 100개이고 예측 클래스 값 유형이 2개(이진분류)라면 반환 값은 100 x 2 ndarray 임\n",
        " - 각 열은 개별 클래스의 예측 확률임. 이진 분류에서 첫 번째 컬럼은 0 Negative 확률, 두번째 컬럼은 1 Positive 확률임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cua9ntwdmDvW",
        "outputId": "4d9d70ad-9f9d-4cf3-b4ce-77fcffe5f705"
      },
      "source": [
        "pred_proba = lr.predict_proba(x_test)\n",
        "pred = lr.predict(x_test)\n",
        "print('pred() 결과:', pred.shape)\n",
        "print('pred array에서 앞 3개만 추출:\\n', pred[:3])\n",
        "print('\\n')\n",
        "print('pred_proba() 결과:', pred_proba.shape)\n",
        "print('pred_proba array에서 앞 3개만 추출:\\n', pred_proba[:3])\n",
        "\n",
        "print('\\n')\n",
        "# 예측 확률 array와 예측 결괏값 array를 병합(concatenate)해 예측 확률과 결괏값을 한눈에 확인\n",
        "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis = 1)\n",
        "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred() 결과: (179,)\n",
            "pred array에서 앞 3개만 추출:\n",
            " [1 0 0]\n",
            "\n",
            "\n",
            "pred_proba() 결과: (179, 2)\n",
            "pred_proba array에서 앞 3개만 추출:\n",
            " [[0.46191519 0.53808481]\n",
            " [0.878675   0.121325  ]\n",
            " [0.87716185 0.12283815]]\n",
            "\n",
            "\n",
            "두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
            " [[0.46191519 0.53808481 1.        ]\n",
            " [0.878675   0.121325   0.        ]\n",
            " [0.87716185 0.12283815 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo9t4xBYn49x"
      },
      "source": [
        "#### Binarizer 클래스 사용법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Jq-FOLn_PL",
        "outputId": "1cb735ba-cce5-40e3-ae7e-7df510ef2998"
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "X = [[1, -1, 2],\n",
        "     [2, 0, 0],\n",
        "     [0, 1.1, 1.2]]\n",
        "\n",
        "# X의 개별 원소들이 threshold 값보다 같거나 작으면 0을, 크면 1을 반환\n",
        "binarizer = Binarizer(threshold = 1.1)\n",
        "print(binarizer.fit_transform(X))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    }
  ]
}